{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cc9965-9c12-4122-8ec6-90fb67118321",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "## Introdução\n",
    "Neste notebook, vamos fazer o webscrapping das imagens dos personagens de anime que serão usadas para treinar e testar a IA reconhecedora, gerando assim nosso dataset.\n",
    "\n",
    "## Sumário\n",
    "1. [Instalação de Bibliotecas](#Instalação-de-Bibliotecas)\n",
    "2. [Inicialização](#Inicialização)\n",
    "3. [Obtenção dos Personagens](#Obtenção-dos-Personagens)\n",
    "4. [Obtenção das Imagens](#Obtenção-das-Imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a36f1-c6fd-45d3-b247-7fe6c36d6603",
   "metadata": {},
   "source": [
    "## Instalação de Bibliotecas\n",
    "\n",
    "Primeiramente, se ainda não foi feito, instalaremos todas as bibliotecas necessárias para esse projeto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57ab0d-1ce2-4db7-9be8-607401aca708",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ecf94-3fcf-4fae-98a6-b56864784855",
   "metadata": {},
   "source": [
    "## Inicialização\n",
    "\n",
    "Agora importaremos as bibliotecas e também inicializaremos as constantes globais que serão usadas a seguir:\n",
    "Será exigido a chave de API do Google Cloud e também o Search Engine ID do motor de busca customizado, eles serão necessários posteriormente. Caso não tenha não insira nada e pode prosseguir até onde for possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae8a24f-2631-447b-800e-4f32111230c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, ResultSet, Tag\n",
    "from PIL import Image\n",
    "\n",
    "CHAR_FOLDER = Path(\"Characters\")\n",
    "TEST_FOLDER = CHAR_FOLDER / Path(\"Test\")\n",
    "TRAIN_FOLDER = CHAR_FOLDER / Path(\"Train\")\n",
    "CHAR_LIST = Path(\"characters.txt\")\n",
    "LINKS_JSON = \"links.json\"\n",
    "API_KEY = input(\"Chave API Google Cloud:\")\n",
    "SEARCH_ENGINE_ID = input(\"Custom Search Engine ID:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab3772",
   "metadata": {},
   "source": [
    "## Obtenção dos Personagens\n",
    "\n",
    "Aqui iremos obter a lista de todos os personagens principais que iremos treinar nossa IA, no caso iremos escolher os personagens do arco do Stardust Crusaders do anime JoJo's Bizarre Adventure, além disso iremos estruturar os diretórios para o salvamento dos arquivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061db5f",
   "metadata": {},
   "source": [
    "### Obtenção da Lista de Nomes\n",
    "\n",
    "Aqui iremos criar um arquivo `characters.txt` com a lista dos nomes dos personagens principais, utilizando o site do MyAnimesList como referência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c22144a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammad Avdol\n",
      "Dio Brando\n",
      "Iggy\n",
      "Joseph Joestar\n",
      "Noriaki Kakyouin\n",
      "Joutarou Kuujou\n",
      "Jean-Pierre Polnareff\n"
     ]
    }
   ],
   "source": [
    "def get_characters(url):\n",
    "    response = requests.get(url)\n",
    "    parsed_html = BeautifulSoup(response.content, \"html.parser\")\n",
    "    characters: ResultSet[Tag] = parsed_html.find_all(\n",
    "        \"h3\", class_=\"h3_character_name\"\n",
    "    )\n",
    "    with open(CHAR_LIST, \"w\", encoding=\"utf-8\") as character_file:\n",
    "        for character in characters:\n",
    "            div_parent: Tag = character.parent.parent.parent\n",
    "            character_role: Tag = div_parent.findChildren(\"div\")[3]\n",
    "            \n",
    "            # Verificamos se o personagem é um personagem principal\n",
    "            if character_role.text.strip() == \"Main\":\n",
    "                \n",
    "                # Como o nome vem no padrão oriental iremos redefinir para o padrão ocidental, caso necessário\n",
    "                character = character.text\n",
    "                if \", \" in character:\n",
    "                    name_split = character.split(\", \")\n",
    "                    character = name_split[1] + \" \" + name_split[0]\n",
    "                print(character)\n",
    "                print(character, file=character_file)\n",
    "\n",
    "url = \"https://myanimelist.net/anime/26055/JoJo_no_Kimyou_na_Bouken_Part_3__Stardust_Crusaders_2nd_Season/characters\"\n",
    "get_characters(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb1926",
   "metadata": {},
   "source": [
    "### Criação da Estrutura das Pastas\n",
    "\n",
    "Agora iremos criar e estruturar as pastas, no qual iremos guardar e separar as imagens, criando uma pasta para cada personagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "174290b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    CHAR_FOLDER.mkdir(exist_ok=True)\n",
    "    TEST_FOLDER.mkdir(exist_ok=True)\n",
    "    TRAIN_FOLDER.mkdir(exist_ok=True)\n",
    "    with open(CHAR_LIST, \"r\", encoding=\"utf-8\") as characters:\n",
    "        for character in characters:\n",
    "            character_name = character.strip().replace(\" \",\"-\")\n",
    "            pasta = TEST_FOLDER / character_name\n",
    "            pasta.mkdir(exist_ok=True)\n",
    "            pasta = TRAIN_FOLDER / character_name\n",
    "            pasta.mkdir(exist_ok=True)\n",
    "\n",
    "create_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fe164",
   "metadata": {},
   "source": [
    "## Obtenção das Imagens\n",
    "\n",
    "Neste trecho iremos obter as imagens de fato, e no caso iremos utilizar API do Google para a obtenção das imagens.\n",
    "\n",
    "**Nota:** Da forma que a obtenção das imagens será apresentado à seguir, não é garantido que as imagens serão boas, portanto faz-se necessário uma revisão manual das imagens e/ou uma re-execução do código com *offset*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c722fff",
   "metadata": {},
   "source": [
    "### Criação da Lista de Links\n",
    "\n",
    "Agora iremos criar um arquivo `links.json` que irá conter a lista com os links das imagens de todos os personagens separando por personagem.\n",
    "No código a seguir é necessário a chave de API e o ID da Search Engine da *Custom Search API* do Google a ser usada para pesquisar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc48da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_links(links: dict):\n",
    "    with open(LINKS_JSON, 'w') as json_file:\n",
    "        json.dump(links, json_file, indent=4)\n",
    "\n",
    "def load_links() -> dict:\n",
    "    if os.path.exists(LINKS_JSON):\n",
    "        with open(LINKS_JSON, 'r') as json_file:\n",
    "            return json.load(json_file)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def fetch_image_links(links: dict[str,list], query: str, api_key: str, cse_id: str, limit=10, offset=0):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'cx': cse_id,\n",
    "        'key': api_key,\n",
    "        'searchType': 'image',\n",
    "        'start': offset + 1,\n",
    "        'num': limit        # Máximo é 10\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        search_results = response.json()\n",
    "        image_links = [item['link'] for item in search_results.get('items', [])]\n",
    "        \n",
    "        # Salva os links das imagens no dict\n",
    "        if len(links[query]) > 0:\n",
    "            links[query] = links[query] + image_links\n",
    "        else:\n",
    "            links[query] = image_links\n",
    "        print(f\"Links das primeiras {limit} imagens de {query} (com offset de {offset}) salvos com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Falha ao acessar a API do Google Custom Search. Status Code: {response.status_code}\")\n",
    "\n",
    "links = load_links()\n",
    "with open(CHAR_LIST,\"r\") as character_list:\n",
    "    for line in character_list:\n",
    "        query = line.strip()\n",
    "        fetch_image_links(links, query,api_key=API_KEY,cse_id=SEARCH_ENGINE_ID) \n",
    "save_links(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda03c2e",
   "metadata": {},
   "source": [
    "### Download das Imagens\n",
    "\n",
    "Agora iremos ler o arquivo `links.json` criado anteriomente e usar a biblioteca Pillow para baixar as imagens, separando 80% das imagens para treino e 20% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91ec7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = load_links()\n",
    "def download_images(links: dict[str, list]):\n",
    "    for character_name, links_list in links.items():\n",
    "        pasta_treino = TRAIN_FOLDER / character_name.strip().replace(\" \", \"-\")\n",
    "        pasta_teste = TEST_FOLDER / character_name.strip().replace(\" \", \"-\")\n",
    "\n",
    "        # Separa as imagens na proporção de 80% para treino e 20% para teste\n",
    "        split_index = int(len(links_list) * 0.8)\n",
    "        treino_links = links_list[:split_index]\n",
    "        teste_links = links_list[split_index:]\n",
    "\n",
    "        # Salva as imagens de treino\n",
    "        for i, link in enumerate(treino_links):\n",
    "            response = requests.get(link)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(pasta_treino / f\"{character_name}_{i}.jpg\")\n",
    "\n",
    "        # Salva as imagens de teste\n",
    "        for i, link in enumerate(teste_links):\n",
    "            response = requests.get(link)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(pasta_teste / f\"{character_name}_{i}.jpg\")\n",
    "\n",
    "download_images(links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
